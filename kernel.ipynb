{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "c386cfd1-3d2e-4bd0-b1bf-2c72698afe96",
    "_uuid": "4cdc8ebf9bc167498cace36993800c819556eb04",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import glob\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from keras.utils import to_categorical\n",
    "from keras.layers import Dense, Input, Conv2D, Flatten, MaxPool2D, Activation, Dropout\n",
    "from keras.constraints import maxnorm\n",
    "from keras.models import Model\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras import backend as K\n",
    "from keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Declaring constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "a42ae61e-565e-48ae-b618-370dc4bd3718",
    "_uuid": "8f087bcd8bb6c49f440bd5bea4769ddd692d291e",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Declaring constants\n",
    "FIG_WIDTH=20 # Width of figure\n",
    "ROW_HEIGHT=3 # Height of each row when showing a figure which consists of multiple rows\n",
    "RESIZE_DIM=28# The images will be resized to 28x28 pixels\n",
    "PIXEL_ADJ = 3 # for adjusting the image croping "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating Path Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "e786b5c7-7f0b-42d4-a3e4-fd4b7d66fbd9",
    "_uuid": "a1454525b854abf797ea8763431da25e7aa99f92",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "data_dir=os.path.join('G:/Numta_Workshop/Numta_Workshop')\n",
    "paths_train_a=glob.glob(os.path.join(data_dir,'training-a','*.png'))\n",
    "paths_train_b=glob.glob(os.path.join(data_dir,'training-b','*.png'))\n",
    "paths_train_e=glob.glob(os.path.join(data_dir,'training-e','*.png'))\n",
    "paths_train_c=glob.glob(os.path.join(data_dir,'training-c','*.png'))\n",
    "paths_train_d=glob.glob(os.path.join(data_dir,'training-d','*.png'))\n",
    "paths_train_all=paths_train_a+paths_train_b+paths_train_c+paths_train_d+paths_train_e\n",
    "\n",
    "paths_test_a=glob.glob(os.path.join(data_dir,'testing-a','*.png'))\n",
    "paths_test_b=glob.glob(os.path.join(data_dir,'testing-b','*.png'))\n",
    "paths_test_e=glob.glob(os.path.join(data_dir,'testing-e','*.png'))\n",
    "paths_test_c=glob.glob(os.path.join(data_dir,'testing-c','*.png'))\n",
    "paths_test_d=glob.glob(os.path.join(data_dir,'testing-d','*.png'))\n",
    "paths_test_f=glob.glob(os.path.join(data_dir,'testing-f','*.png'))+glob.glob(os.path.join(data_dir,'testing-f','*.JPG'))\n",
    "paths_test_auga=glob.glob(os.path.join(data_dir,'testing-auga','*.png'))\n",
    "paths_test_augc=glob.glob(os.path.join(data_dir,'testing-augc','*.png'))\n",
    "paths_test_all=paths_test_a+paths_test_b+paths_test_c+paths_test_d+paths_test_e+paths_test_f+paths_test_auga+paths_test_augc\n",
    "\n",
    "path_label_train_a=os.path.join(data_dir,'training-a.csv')\n",
    "path_label_train_b=os.path.join(data_dir,'training-b.csv')\n",
    "path_label_train_e=os.path.join(data_dir,'training-e.csv')\n",
    "path_label_train_c=os.path.join(data_dir,'training-c.csv')\n",
    "path_label_train_d=os.path.join(data_dir,'training-d.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "45ef7b96-b4cb-46d5-a092-6eb10775cb3e",
    "_uuid": "5aab8d2c6139e67da8cac46a41b02dd3b0c16c1a"
   },
   "source": [
    "# Utility Functions and Functions that make the dataset augmented"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "87d7081d-aa4a-48b9-b1a4-575ceceb2eb3",
    "_uuid": "aa19885280eef5dfed1f8378d668ea7f025a7925",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_key(path):\n",
    "    # seperates the key of an image from the filepath\n",
    "    key=path.split(os.sep)[-1] # os.sep = '/' and [-1] refers to the last element of the list\n",
    "    return key\n",
    "\n",
    "#Data-set doesn't contain horizontal or vertical flips, worthy enough to be ignored.\n",
    "\n",
    "#Random-rotating the images\n",
    "\n",
    "def get_augmented_rotate(path):\n",
    "    img=cv2.imread(path,cv2.IMREAD_GRAYSCALE) # read image, image size is 180x180\n",
    "    img=255-img\n",
    "    img = cv2.resize(img, (RESIZE_DIM,RESIZE_DIM) ,interpolation=cv2.INTER_AREA)\n",
    "  \n",
    " \n",
    "    M = cv2.getRotationMatrix2D((RESIZE_DIM/2,RESIZE_DIM/2),np.random.randint(1,90),1)\n",
    "    dst = cv2.warpAffine(img,M,(RESIZE_DIM,RESIZE_DIM))\n",
    "    \n",
    "    gaussian_3 = cv2.GaussianBlur(dst, (9,9), 10.0) #unblur\n",
    "    img = cv2.addWeighted(dst, 1.5, gaussian_3, -0.5, 0, dst)\n",
    "    kernel = np.array([[-1,-1,-1], [-1,9,-1], [-1,-1,-1]]) #filter\n",
    "    img = cv2.filter2D(img, -1, kernel)\n",
    "    ret,img = cv2.threshold(img, 128, 255, cv2.THRESH_BINARY_INV+cv2.THRESH_OTSU)  \n",
    "    \n",
    "    \n",
    "    return dst\n",
    "\n",
    "#Samplewise_centers\n",
    "def get_augmented_blur(path):\n",
    "    img=cv2.imread(path,cv2.IMREAD_GRAYSCALE) # read image, image size is 180x180\n",
    "    img=255-img\n",
    "    img = cv2.resize(img, (RESIZE_DIM,RESIZE_DIM) ,interpolation=cv2.INTER_AREA)\n",
    "    \n",
    "    \n",
    "    kernel = np.ones((9,9),np.float32)/80\n",
    "    dst = cv2.filter2D(img,-1,kernel)\n",
    "    \n",
    "    gaussian_3 = cv2.GaussianBlur(dst, (9,9), 10.0) #unblur\n",
    "    img = cv2.addWeighted(img, 1.5, gaussian_3, -0.5, 0, img)\n",
    "    kernel = np.array([[-1,-1,-1], [-1,9,-1], [-1,-1,-1]]) #filter\n",
    "    img = cv2.filter2D(img, -1, kernel)\n",
    "    ret,img = cv2.threshold(img, 128, 255, cv2.THRESH_BINARY_INV+cv2.THRESH_OTSU)  \n",
    "    return dst\n",
    "\n",
    "\n",
    "def get_augmented_zca_whitening(train_data,val_data):\n",
    "    datagen = ImageDataGenerator(zca_whitening=True)\n",
    "    train_data = train_data.reshape(-1, RESIZE_DIM,RESIZE_DIM,1)\n",
    "    datagen.fit(train_data)\n",
    "    for X_batch in datagen.flow(train_data, batch_size=len(train_data)):\n",
    "        x=len(train_data)\n",
    "        zca_img =[]\n",
    "        for i in range(0, x):\n",
    "            X_batch=X_batch.reshape(-1,RESIZE_DIM,RESIZE_DIM)\n",
    "            X_batch[i]= X_batch[i].reshape(RESIZE_DIM,RESIZE_DIM)\n",
    "            zca_img.append(X_batch[i])\n",
    "        break\n",
    "    zca_img = np.asarray(zca_img)\n",
    "    return zca_img,val_data\n",
    "\n",
    "\n",
    "def get_augmented_shear_range(path):\n",
    "    datagen = ImageDataGenerator(shear_range = 50)\n",
    "    # fit parameters from data\n",
    "    img=cv2.imread(path,cv2.IMREAD_GRAYSCALE) # read image, image size is 180x180\n",
    "    img=255-img\n",
    "    img = cv2.resize(img, (RESIZE_DIM,RESIZE_DIM) ,interpolation=cv2.INTER_AREA)\n",
    "    gaussian_3 = cv2.GaussianBlur(img, (9,9), 10.0) #unblur\n",
    "    img = cv2.addWeighted(img, 1.5, gaussian_3, -0.5, 0, img)\n",
    "    kernel = np.array([[-1,-1,-1], [-1,9,-1], [-1,-1,-1]]) #filter\n",
    "    img = cv2.filter2D(img, -1, kernel)\n",
    "    ret,img = cv2.threshold(img, 128, 255, cv2.THRESH_BINARY_INV+cv2.THRESH_OTSU)  \n",
    "    \n",
    "    img = img.reshape(1, RESIZE_DIM, RESIZE_DIM, 1)\n",
    "    # configure batch size and retrieve one batch of images\n",
    "    for X_batch in datagen.flow(img):\n",
    "    # create a grid of 3x3 images\n",
    "\n",
    "        for i in range(0, 1):\n",
    "            X_batch=X_batch.reshape(-1,RESIZE_DIM,RESIZE_DIM)\n",
    "            \n",
    "            X_batch[0]= X_batch[0].reshape(RESIZE_DIM,RESIZE_DIM)\n",
    "        break\n",
    "    return X_batch[0]\n",
    "\n",
    "def get_augmented_wshift(path):\n",
    "    datagen = ImageDataGenerator(width_shift_range = 25)\n",
    "    # fit parameters from data\n",
    "    img=cv2.imread(path,cv2.IMREAD_GRAYSCALE) # read image, image size is 180x180\n",
    "    img=255-img\n",
    "    img = cv2.resize(img, (RESIZE_DIM,RESIZE_DIM) ,interpolation=cv2.INTER_AREA)\n",
    "    gaussian_3 = cv2.GaussianBlur(img, (9,9), 10.0) #unblur\n",
    "    img = cv2.addWeighted(img, 1.5, gaussian_3, -0.5, 0, img)\n",
    "    kernel = np.array([[-1,-1,-1], [-1,9,-1], [-1,-1,-1]]) #filter\n",
    "    img = cv2.filter2D(img, -1, kernel)\n",
    "    ret,img = cv2.threshold(img, 128, 255, cv2.THRESH_BINARY_INV+cv2.THRESH_OTSU)  \n",
    "    \n",
    "    img = img.reshape(1, RESIZE_DIM, RESIZE_DIM, 1)\n",
    "    # configure batch size and retrieve one batch of images\n",
    "    for X_batch in datagen.flow(img):\n",
    "    # create a grid of 3x3 images\n",
    "\n",
    "        for i in range(0, 1):\n",
    "            X_batch=X_batch.reshape(-1,RESIZE_DIM,RESIZE_DIM)\n",
    "            X_batch[0]= X_batch[0].reshape(RESIZE_DIM,RESIZE_DIM)\n",
    "        break\n",
    "    return X_batch[0]\n",
    "\n",
    "\n",
    "def get_augmented_hshift(path):\n",
    "    datagen = ImageDataGenerator(height_shift_range = 25)\n",
    "    # fit parameters from data\n",
    "    img=cv2.imread(path,cv2.IMREAD_GRAYSCALE) # read image, image size is 180x180\n",
    "    img=255-img\n",
    "    img = cv2.resize(img, (RESIZE_DIM,RESIZE_DIM) ,interpolation=cv2.INTER_AREA)\n",
    "    gaussian_3 = cv2.GaussianBlur(img, (9,9), 10.0) #unblur\n",
    "    img = cv2.addWeighted(img, 1.5, gaussian_3, -0.5, 0, img)\n",
    "    kernel = np.array([[-1,-1,-1], [-1,9,-1], [-1,-1,-1]]) #filter\n",
    "    img = cv2.filter2D(img, -1, kernel)\n",
    "    ret,img = cv2.threshold(img, 128, 255, cv2.THRESH_BINARY_INV+cv2.THRESH_OTSU)  \n",
    "    \n",
    "    img = img.reshape(1, RESIZE_DIM, RESIZE_DIM, 1)\n",
    "    # configure batch size and retrieve one batch of images\n",
    "    for X_batch in datagen.flow(img):\n",
    "    # create a grid of 3x3 images\n",
    "\n",
    "        for i in range(0, 1):\n",
    "            X_batch=X_batch.reshape(-1,28,28)\n",
    "            X_batch[0]= X_batch[0].reshape(28,28)\n",
    "        break\n",
    "    return X_batch[0]\n",
    "\n",
    "\n",
    "def get_augmented_w_h_shift(path):\n",
    "    datagen = ImageDataGenerator(height_shift_range = 25,width_shift_range = 25)\n",
    "    # fit parameters from data\n",
    "    img=cv2.imread(path,cv2.IMREAD_GRAYSCALE) # read image, image size is 180x180\n",
    "    img=255-img\n",
    "    img = cv2.resize(img, (RESIZE_DIM,RESIZE_DIM) ,interpolation=cv2.INTER_AREA)\n",
    "    gaussian_3 = cv2.GaussianBlur(img, (9,9), 10.0) #unblur\n",
    "    img = cv2.addWeighted(img, 1.5, gaussian_3, -0.5, 0, img)\n",
    "    kernel = np.array([[-1,-1,-1], [-1,9,-1], [-1,-1,-1]]) #filter\n",
    "    img = cv2.filter2D(img, -1, kernel)\n",
    "    ret,img = cv2.threshold(img, 128, 255, cv2.THRESH_BINARY_INV+cv2.THRESH_OTSU)  \n",
    "    \n",
    "    img = img.reshape(1, RESIZE_DIM, RESIZE_DIM, 1)\n",
    "    img = img.reshape(1, RESIZE_DIM, RESIZE_DIM, 1)\n",
    "    # configure batch size and retrieve one batch of images\n",
    "    for X_batch in datagen.flow(img):\n",
    "    # create a grid of 3x3 images\n",
    "\n",
    "        for i in range(0, 1):\n",
    "            X_batch=X_batch.reshape(-1,28,28)\n",
    "            X_batch[0]= X_batch[0].reshape(28,28)\n",
    "        break\n",
    "    return X_batch[0]\n",
    "\n",
    "\n",
    "\n",
    "def get_data_aug(paths_img,path_label=None,resize_dim=None):\n",
    "    '''reads images from the filepaths, resizes them (if given), and returns them in a numpy array\n",
    "    Args:\n",
    "        paths_img: image filepaths\n",
    "        path_label: pass image label filepaths while processing training data, defaults to None while processing testing data\n",
    "        resize_dim: if given, the image is resized to resize_dim x resize_dim (optional)\n",
    "    Returns:\n",
    "        X: group of images\n",
    "        y: categorical true labels\n",
    "    '''\n",
    "    X=[] # initialize empty list for resized images\n",
    "    for i,path in enumerate(paths_img): # details about enumerate is on : https://stackoverflow.com/questions/22171558/what-does-enumerate-mean\n",
    "        #img=img_crop(path)\n",
    "        img=get_augmented_rotate(path)\n",
    "        X.append(img) # expand image to 28x28x1 and append to the list\n",
    "        # display progress\n",
    "        if i==len(paths_img)-1:\n",
    "            end='\\n'\n",
    "        else:\n",
    "            end='\\r'\n",
    "        print('processed {}/{}'.format(i+1,len(paths_img)),end=end)\n",
    "        \n",
    "    X=np.array(X) # tranform list to numpy array\n",
    "    if  path_label is None:\n",
    "        return X\n",
    "    else:\n",
    "        df = pd.read_csv(path_label) # read labels\n",
    "        df=df.set_index('filename')  \n",
    "        #by the upper line of code we are saying that we won't be using the conventional 0,1,2 indexing but we will be using the filenames as the index for each row data\n",
    "        y_label=[df.loc[get_key(path)]['digit'] for path in  paths_img] # get the labels corresponding to the images\n",
    "        #first the for loop creates path for all the the image file then only the image name is exracted from the path with the help of the function get_key\n",
    "        #this filename is used as the index of the csv file and we are interested only the digit value of that image and therefore ['digit'] part\n",
    "        y=to_categorical(y_label,10) # transfrom integer value to categorical variable\n",
    "        return X, y\n",
    "    \n",
    "def get_data_aug2(paths_img,path_label=None,resize_dim=None):\n",
    "    '''reads images from the filepaths, resizes them (if given), and returns them in a numpy array\n",
    "    Args:\n",
    "        paths_img: image filepaths\n",
    "        path_label: pass image label filepaths while processing training data, defaults to None while processing testing data\n",
    "        resize_dim: if given, the image is resized to resize_dim x resize_dim (optional)\n",
    "    Returns:\n",
    "        X: group of images\n",
    "        y: categorical true labels\n",
    "    '''\n",
    "    X=[] # initialize empty list for resized images\n",
    "    for i,path in enumerate(paths_img): # details about enumerate is on : https://stackoverflow.com/questions/22171558/what-does-enumerate-mean\n",
    "        #img=img_crop(path)\n",
    "        img=get_augmented_blur(path)\n",
    "        X.append(img) # expand image to 28x28x1 and append to the list\n",
    "        # display progress\n",
    "        if i==len(paths_img)-1:\n",
    "            end='\\n'\n",
    "        else: \n",
    "            end='\\r'\n",
    "        print('processed {}/{}'.format(i+1,len(paths_img)),end=end)\n",
    "        \n",
    "    X=np.array(X) # tranform list to numpy array\n",
    "    if  path_label is None:\n",
    "        return X\n",
    "    else:\n",
    "        df = pd.read_csv(path_label) # read labels\n",
    "        df=df.set_index('filename')  \n",
    "        #by the upper line of code we are saying that we won't be using the conventional 0,1,2 indexing but we will be using the filenames as the index for each row data\n",
    "        y_label=[df.loc[get_key(path)]['digit'] for path in  paths_img] # get the labels corresponding to the images\n",
    "        #first the for loop creates path for all the the image file then only the image name is exracted from the path with the help of the function get_key\n",
    "        #this filename is used as the index of the csv file and we are interested only the digit value of that image and therefore ['digit'] part\n",
    "        y=to_categorical(y_label,10) # transfrom integer value to categorical variable\n",
    "        return X, y\n",
    "    \n",
    "\n",
    "def get_data_aug4(paths_img,path_label=None,resize_dim=None):\n",
    "    '''reads images from the filepaths, resizes them (if given), and returns them in a numpy array\n",
    "    Args:\n",
    "        paths_img: image filepaths\n",
    "        path_label: pass image label filepaths while processing training data, defaults to None while processing testing data\n",
    "        resize_dim: if given, the image is resized to resize_dim x resize_dim (optional)\n",
    "    Returns:\n",
    "        X: group of images\n",
    "        y: categorical true labels\n",
    "    '''\n",
    "    X=[] # initialize empty list for resized images\n",
    "    for i,path in enumerate(paths_img): # details about enumerate is on : https://stackoverflow.com/questions/22171558/what-does-enumerate-mean\n",
    "        #img=img_crop(path)\n",
    "        img=get_augmented_shear_range(path)\n",
    "        X.append(img) # expand image to 28x28x1 and append to the list\n",
    "        # display progress\n",
    "        if i==len(paths_img)-1:\n",
    "            end='\\n'\n",
    "        else: \n",
    "            end='\\r'\n",
    "        print('processed {}/{}'.format(i+1,len(paths_img)),end=end)\n",
    "        \n",
    "    X=np.array(X) # tranform list to numpy array\n",
    "    if  path_label is None:\n",
    "        return X\n",
    "    else:\n",
    "        df = pd.read_csv(path_label) # read labels\n",
    "        df=df.set_index('filename')  \n",
    "        #by the upper line of code we are saying that we won't be using the conventional 0,1,2 indexing but we will be using the filenames as the index for each row data\n",
    "        y_label=[df.loc[get_key(path)]['digit'] for path in  paths_img] # get the labels corresponding to the images\n",
    "        #first the for loop creates path for all the the image file then only the image name is exracted from the path with the help of the function get_key\n",
    "        #this filename is used as the index of the csv file and we are interested only the digit value of that image and therefore ['digit'] part\n",
    "        y=to_categorical(y_label,10) # transfrom integer value to categorical variable\n",
    "        return X, y\n",
    "\n",
    "def get_data_aug5(paths_img,path_label=None,resize_dim=None):\n",
    "    '''reads images from the filepaths, resizes them (if given), and returns them in a numpy array\n",
    "    Args:\n",
    "        paths_img: image filepaths\n",
    "        path_label: pass image label filepaths while processing training data, defaults to None while processing testing data\n",
    "        resize_dim: if given, the image is resized to resize_dim x resize_dim (optional)\n",
    "    Returns:\n",
    "        X: group of images\n",
    "        y: categorical true labels\n",
    "    '''\n",
    "    X=[] # initialize empty list for resized images\n",
    "    for i,path in enumerate(paths_img): # details about enumerate is on : https://stackoverflow.com/questions/22171558/what-does-enumerate-mean\n",
    "        #img=img_crop(path)\n",
    "        img=get_augmented_wshift(path)\n",
    "        X.append(img) # expand image to 28x28x1 and append to the list\n",
    "        # display progress\n",
    "        if i==len(paths_img)-1:\n",
    "            end='\\n'\n",
    "        else: \n",
    "            end='\\r'\n",
    "        print('processed {}/{}'.format(i+1,len(paths_img)),end=end)\n",
    "        \n",
    "    X=np.array(X) # tranform list to numpy array\n",
    "    if  path_label is None:\n",
    "        return X\n",
    "    else:\n",
    "        df = pd.read_csv(path_label) # read labels\n",
    "        df=df.set_index('filename')  \n",
    "        #by the upper line of code we are saying that we won't be using the conventional 0,1,2 indexing but we will be using the filenames as the index for each row data\n",
    "        y_label=[df.loc[get_key(path)]['digit'] for path in  paths_img] # get the labels corresponding to the images\n",
    "        #first the for loop creates path for all the the image file then only the image name is exracted from the path with the help of the function get_key\n",
    "        #this filename is used as the index of the csv file and we are interested only the digit value of that image and therefore ['digit'] part\n",
    "        y=to_categorical(y_label,10) # transfrom integer value to categorical variable\n",
    "        return X, y\n",
    "    \n",
    "def get_data_aug6(paths_img,path_label=None,resize_dim=None):\n",
    "    '''reads images from the filepaths, resizes them (if given), and returns them in a numpy array\n",
    "    Args:\n",
    "        paths_img: image filepaths\n",
    "        path_label: pass image label filepaths while processing training data, defaults to None while processing testing data\n",
    "        resize_dim: if given, the image is resized to resize_dim x resize_dim (optional)\n",
    "    Returns:\n",
    "        X: group of images\n",
    "        y: categorical true labels\n",
    "    '''\n",
    "    X=[] # initialize empty list for resized images\n",
    "    for i,path in enumerate(paths_img): # details about enumerate is on : https://stackoverflow.com/questions/22171558/what-does-enumerate-mean\n",
    "        #img=img_crop(path)\n",
    "        img=get_augmented_hshift(path)\n",
    "        X.append(img) # expand image to 28x28x1 and append to the list\n",
    "        # display progress\n",
    "        if i==len(paths_img)-1:\n",
    "            end='\\n'\n",
    "        else: \n",
    "            end='\\r'\n",
    "        print('processed {}/{}'.format(i+1,len(paths_img)),end=end)\n",
    "        \n",
    "    X=np.array(X) # tranform list to numpy array\n",
    "    if  path_label is None:\n",
    "        return X\n",
    "    else:\n",
    "        df = pd.read_csv(path_label) # read labels\n",
    "        df=df.set_index('filename')  \n",
    "        #by the upper line of code we are saying that we won't be using the conventional 0,1,2 indexing but we will be using the filenames as the index for each row data\n",
    "        y_label=[df.loc[get_key(path)]['digit'] for path in  paths_img] # get the labels corresponding to the images\n",
    "        #first the for loop creates path for all the the image file then only the image name is exracted from the path with the help of the function get_key\n",
    "        #this filename is used as the index of the csv file and we are interested only the digit value of that image and therefore ['digit'] part\n",
    "        y=to_categorical(y_label,10) # transfrom integer value to categorical variable\n",
    "        return X, y\n",
    "\n",
    "def get_data_aug7(paths_img,path_label=None,resize_dim=None):\n",
    "    '''reads images from the filepaths, resizes them (if given), and returns them in a numpy array\n",
    "    Args:\n",
    "        paths_img: image filepaths\n",
    "        path_label: pass image label filepaths while processing training data, defaults to None while processing testing data\n",
    "        resize_dim: if given, the image is resized to resize_dim x resize_dim (optional)\n",
    "    Returns:\n",
    "        X: group of images\n",
    "        y: categorical true labels\n",
    "    '''\n",
    "    X=[] # initialize empty list for resized images\n",
    "    for i,path in enumerate(paths_img): # details about enumerate is on : https://stackoverflow.com/questions/22171558/what-does-enumerate-mean\n",
    "        #img=img_crop(path)\n",
    "        img=get_augmented_w_h_shift(path)\n",
    "        X.append(img) # expand image to 28x28x1 and append to the list\n",
    "        # display progress\n",
    "        if i==len(paths_img)-1:\n",
    "            end='\\n'\n",
    "        else: end='\\r'\n",
    "        print('processed {}/{}'.format(i+1,len(paths_img)),end=end)\n",
    "        \n",
    "    X=np.array(X) # tranform list to numpy array\n",
    "    if  path_label is None:\n",
    "        return X\n",
    "    else:\n",
    "        df = pd.read_csv(path_label) # read labels\n",
    "        df=df.set_index('filename')  \n",
    "        #by the upper line of code we are saying that we won't be using the conventional 0,1,2 indexing but we will be using the filenames as the index for each row data\n",
    "        y_label=[df.loc[get_key(path)]['digit'] for path in  paths_img] # get the labels corresponding to the images\n",
    "        #first the for loop creates path for all the the image file then only the image name is exracted from the path with the help of the function get_key\n",
    "        #this filename is used as the index of the csv file and we are interested only the digit value of that image and therefore ['digit'] part\n",
    "        y=to_categorical(y_label,10) # transfrom integer value to categorical variable\n",
    "        return X, y\n",
    "\n",
    "\n",
    "def get_data(paths_img,path_label=None,resize_dim=None):\n",
    "    '''reads images from the filepaths, resizes them (if given), and returns them in a numpy array\n",
    "    Args:\n",
    "        paths_img: image filepaths\n",
    "        path_label: pass image label filepaths while processing training data, defaults to None while processing testing data\n",
    "        resize_dim: if given, the image is resized to resize_dim x resize_dim (optional)\n",
    "    Returns:\n",
    "        X: group of images\n",
    "        y: categorical true labels\n",
    "    '''\n",
    "    X=[] # initialize empty list for resized images\n",
    "    \n",
    "    for i,path in enumerate(paths_img): # details about enumerate is on : https://stackoverflow.com/questions/22171558/what-does-enumerate-mean\n",
    "        img=cv2.imread(path,cv2.IMREAD_GRAYSCALE)\n",
    "        img=255-img\n",
    "        if resize_dim is not None:\n",
    "            try:\n",
    "                img=cv2.resize(img,(resize_dim,resize_dim),interpolation=cv2.INTER_AREA) # resize image to 28x28\n",
    "#            X.append(np.expand_dims(img,axis=2)) # expand image to 28x28x1 and append to the list.\n",
    "                \n",
    "            except:\n",
    "                print('The image at %s could not be resized after cropping\\n so we are using the previous method'  %path)\n",
    "                img=cv2.imread(path,cv2.IMREAD_GRAYSCALE) # read image, image size is 180x180\n",
    "                img=255-img\n",
    "                img=cv2.resize(img,(resize_dim,resize_dim),interpolation=cv2.INTER_AREA)\n",
    "        #Attempt at using a Gaussian filter here:\n",
    "        \n",
    "        gaussian_3 = cv2.GaussianBlur(img, (9,9), 10.0) #unblur\n",
    "        img = cv2.addWeighted(img, 1.5, gaussian_3, -0.5, 0, img)\n",
    "        kernel = np.array([[-1,-1,-1], [-1,9,-1], [-1,-1,-1]]) #filter\n",
    "        img = cv2.filter2D(img, -1, kernel)\n",
    "        #thresh = 200\n",
    "        #maxValue = 255\n",
    "        #th, img = cv2.threshold(img, thresh, maxValue, cv2.THRESH_BINARY);\n",
    "        ret,img = cv2.threshold(img, 128, 255, cv2.THRESH_BINARY_INV+cv2.THRESH_OTSU)        \n",
    "        \n",
    "        \n",
    "        X.append(img) # expand image to 28x28x1 and append to the list\n",
    "        # display progress\n",
    "        if i==len(paths_img)-1:\n",
    "            end='\\n'\n",
    "        else: end='\\r'\n",
    "        print('processed {}/{}'.format(i+1,len(paths_img)),end=end)\n",
    "        \n",
    "    X=np.array(X) # tranform list to numpy array\n",
    "    if  path_label is None:\n",
    "        return X\n",
    "    else:\n",
    "        df = pd.read_csv(path_label) # read labels\n",
    "        df=df.set_index('filename')  \n",
    "        #by the upper line of code we are saying that we won't be using the conventional 0,1,2 indexing but we will be using the filenames as the index for each row data\n",
    "        y_label=[df.loc[get_key(path)]['digit'] for path in  paths_img] # get the labels corresponding to the images\n",
    "        #first the for loop creates path for all the the image file then only the image name is exracted from the path with the help of the function get_key\n",
    "        #this filename is used as the index of the csv file and we are interested only the digit value of that image and therefore ['digit'] part\n",
    "        y=to_categorical(y_label,10) # transfrom integer value to categorical variable\n",
    "        return X, y\n",
    "\n",
    "def imshow_group(X,y=None,y_pred=None,n_per_row=10):\n",
    "    '''helper function to visualize a group of images along with their categorical true labels (y) and prediction probabilities.\n",
    "    Args:\n",
    "        X: images\n",
    "        y: categorical true labels\n",
    "        y_pred: predicted class probabilities\n",
    "        n_per_row: number of images per row to be plotted\n",
    "    '''\n",
    "    n_sample=len(X)\n",
    "    img_dim=X.shape[1]\n",
    "    \n",
    "    j=np.ceil(n_sample/n_per_row)\n",
    "    \n",
    "    fig=plt.figure(figsize=(FIG_WIDTH,ROW_HEIGHT*j))\n",
    "    \n",
    "    for i,img in enumerate(X):\n",
    "        plt.subplot(j,n_per_row,i+1)\n",
    "        plt.imshow(img, cmap='gray')\n",
    "        if y is not None:\n",
    "                plt.title('true label: {}'.format(np.argmax(y[i])))\n",
    "                #argmax function finds the maximum elemant value in an array and returns that elements index number\n",
    "        if y_pred is not None:\n",
    "            top_n=3 # top 3 predictions with highest probabilities\n",
    "            \n",
    "            ind_sorted=np.argsort(y_pred[i])[::-1] \n",
    "            #^ this line of code basically sort the array in an ascending order by their index value\n",
    "            #for example if you give an array like this : [-9,-4,-1,0,1,8,6,2,-10,0] the fuction will return an array like this : [8, 0, 1, 2, 3, 9, 4, 7, 6, 5]\n",
    "            #the -1 part select the last element\n",
    "            h=img_dim+4\n",
    "            \n",
    "            for k in range(top_n):\n",
    "                string='pred: {} ({:.0f}%)\\n'.format(ind_sorted[k],y_pred[i,ind_sorted[k]]*100)\n",
    "                plt.text(img_dim/2, h, string, horizontalalignment='center',verticalalignment='center')\n",
    "                h+=4\n",
    "        plt.axis('off')\n",
    "    plt.show()   #shows the plot\n",
    "    \n",
    "    \n",
    "    \n",
    "def create_submission(predictions,keys,path):\n",
    "    result = pd.DataFrame(\n",
    "        predictions,\n",
    "        columns=['label'],\n",
    "        index=keys\n",
    "        )\n",
    "    result.index.name='key'\n",
    "    result.to_csv(path, index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "541cbb22-5319-490a-b6a4-8999db770722",
    "_uuid": "01fee24b540458889ebaa9d86b7646e5264e5b1e"
   },
   "source": [
    "# Preprocess data using utility functions and augment each data in 7 ways"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "e4d65fdcac01f5d367ce863d79d22fbbf9b36b86",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train_a,y_train_a=get_data(paths_train_a,path_label_train_a,resize_dim=RESIZE_DIM)\n",
    "X_train_b,y_train_b=get_data(paths_train_b,path_label_train_b,resize_dim=RESIZE_DIM)\n",
    "X_train_c,y_train_c=get_data(paths_train_c,path_label_train_c,resize_dim=RESIZE_DIM)\n",
    "X_train_d,y_train_d=get_data(paths_train_d,path_label_train_d,resize_dim=RESIZE_DIM)\n",
    "X_train_e,y_train_e=get_data(paths_train_e,path_label_train_e,resize_dim=RESIZE_DIM)\n",
    "\n",
    "\n",
    "#Extra dataset after applying various transformations on the image\n",
    "X_train_aug_rotate, y_train_aug_rotate = get_data_aug(paths_train_a,path_label_train_a,resize_dim=RESIZE_DIM)\n",
    "X_train_aug_shear, y_train_aug_shear = get_data_aug4(paths_train_a,path_label_train_a,resize_dim=RESIZE_DIM)\n",
    "X_train_aug_wshift, y_train_aug_wshift = get_data_aug5(paths_train_a,path_label_train_a,resize_dim=RESIZE_DIM)\n",
    "X_train_aug_hshift, y_train_aug_hshift = get_data_aug6(paths_train_a,path_label_train_a,resize_dim=RESIZE_DIM)\n",
    "X_train_w_h_shift, y_train_w_h_shift = get_data_aug7(paths_train_a,path_label_train_a,resize_dim=RESIZE_DIM)\n",
    "X_train_aug_blur, y_train_aug_blur = get_data_aug2(paths_train_a,path_label_train_a,resize_dim=RESIZE_DIM)\n",
    "\n",
    "#zca\n",
    "X_train_aug_zca, y_train_aug_zca = get_augmented_zca_whitening(X_train_a,y_train_a)\n",
    "\n",
    "\n",
    "\n",
    "#Now add train b to the following as well\n",
    "\n",
    "\n",
    "X_train_aug_rotate2, y_train_aug_rotate2 = get_data_aug(paths_train_b,path_label_train_b,resize_dim=RESIZE_DIM)\n",
    "X_train_aug_shear2, y_train_aug_shear2 = get_data_aug4(paths_train_b,path_label_train_b,resize_dim=RESIZE_DIM)\n",
    "X_train_aug_wshift2, y_train_aug_wshift2 = get_data_aug5(paths_train_b,path_label_train_b,resize_dim=RESIZE_DIM)\n",
    "X_train_aug_hshift2, y_train_aug_hshift2 = get_data_aug6(paths_train_b,path_label_train_b,resize_dim=RESIZE_DIM)\n",
    "X_train_w_h_shift2, y_train_w_h_shift2 = get_data_aug7(paths_train_b,path_label_train_b,resize_dim=RESIZE_DIM)\n",
    "X_train_aug_blur2, y_train_aug_blur2 = get_data_aug2(paths_train_b,path_label_train_b,resize_dim=RESIZE_DIM)\n",
    "\n",
    "#zca\n",
    "X_train_aug_zca2, y_train_aug_zca2 = get_augmented_zca_whitening(X_train_b,y_train_b)\n",
    "\n",
    "X_train_aug_rotate3, y_train_aug_rotate3 = get_data_aug(paths_train_c,path_label_train_c,resize_dim=RESIZE_DIM)\n",
    "X_train_aug_shear3, y_train_aug_shear3 = get_data_aug4(paths_train_c,path_label_train_c,resize_dim=RESIZE_DIM)\n",
    "X_train_aug_wshift3, y_train_aug_wshift3 = get_data_aug5(paths_train_c,path_label_train_c,resize_dim=RESIZE_DIM)\n",
    "X_train_aug_hshift3, y_train_aug_hshift3 = get_data_aug6(paths_train_c,path_label_train_c,resize_dim=RESIZE_DIM)\n",
    "X_train_w_h_shift3, y_train_w_h_shift3 = get_data_aug7(paths_train_c,path_label_train_c,resize_dim=RESIZE_DIM)\n",
    "X_train_aug_blur3, y_train_aug_blur3 = get_data_aug2(paths_train_c,path_label_train_c,resize_dim=RESIZE_DIM)\n",
    "\n",
    "#zca\n",
    "X_train_aug_zca3, y_train_aug_zca3 = get_augmented_zca_whitening(X_train_c,y_train_c)\n",
    "\n",
    "\n",
    "X_train_aug_rotate4, y_train_aug_rotate4 = get_data_aug(paths_train_d,path_label_train_d,resize_dim=RESIZE_DIM)\n",
    "X_train_aug_shear4, y_train_aug_shear4 = get_data_aug4(paths_train_d,path_label_train_d,resize_dim=RESIZE_DIM)\n",
    "X_train_aug_wshift4, y_train_aug_wshift4 = get_data_aug5(paths_train_d,path_label_train_d,resize_dim=RESIZE_DIM)\n",
    "X_train_aug_hshift4, y_train_aug_hshift4 = get_data_aug6(paths_train_d,path_label_train_d,resize_dim=RESIZE_DIM)\n",
    "X_train_w_h_shift4, y_train_w_h_shift4 = get_data_aug7(paths_train_d,path_label_train_d,resize_dim=RESIZE_DIM)\n",
    "X_train_aug_blur4, y_train_aug_blur4 = get_data_aug2(paths_train_d,path_label_train_d,resize_dim=RESIZE_DIM)\n",
    "\n",
    "#zca\n",
    "X_train_aug_zca4, y_train_aug_zca4 = get_augmented_zca_whitening(X_train_d,y_train_d)\n",
    "\n",
    "\n",
    "X_train_aug_rotate5, y_train_aug_rotate5 = get_data_aug(paths_train_e,path_label_train_e,resize_dim=RESIZE_DIM)\n",
    "X_train_aug_shear5, y_train_aug_shear5 = get_data_aug4(paths_train_e,path_label_train_e,resize_dim=RESIZE_DIM)\n",
    "X_train_aug_wshift5, y_train_aug_wshift5 = get_data_aug5(paths_train_e,path_label_train_e,resize_dim=RESIZE_DIM)\n",
    "X_train_aug_hshift5, y_train_aug_hshift5 = get_data_aug6(paths_train_e,path_label_train_e,resize_dim=RESIZE_DIM)\n",
    "X_train_w_h_shift5, y_train_w_h_shift5 = get_data_aug7(paths_train_e,path_label_train_e,resize_dim=RESIZE_DIM)\n",
    "X_train_aug_blur5, y_train_aug_blur5 = get_data_aug2(paths_train_e,path_label_train_e,resize_dim=RESIZE_DIM)\n",
    "\n",
    "#zca\n",
    "X_train_aug_zca5, y_train_aug_zca5 = get_augmented_zca_whitening(X_train_e,y_train_e)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Concatenate all data in one variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "0d111deae34f1e29aca3417f5eaa47d0f06067ba",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train_all=np.concatenate((X_train_a,X_train_b,X_train_c,X_train_d,X_train_e,X_train_aug_rotate, X_train_aug_shear, X_train_aug_wshift, X_train_aug_hshift,X_train_w_h_shift,X_train_aug_blur, X_train_aug_zca, X_train_aug_rotate2, X_train_aug_shear2, X_train_aug_wshift2, X_train_aug_hshift2,X_train_w_h_shift2,X_train_aug_blur2, X_train_aug_zca2,X_train_aug_rotate3, X_train_aug_shear3, X_train_aug_wshift3, X_train_aug_hshift3,X_train_w_h_shift3,X_train_aug_blur3, X_train_aug_zca3,X_train_aug_rotate4, X_train_aug_shear4, X_train_aug_wshift4, X_train_aug_hshift4,X_train_w_h_shift4,X_train_aug_blur4, X_train_aug_zca4,X_train_aug_rotate5, X_train_aug_shear5, X_train_aug_wshift5, X_train_aug_hshift5,X_train_w_h_shift5,X_train_aug_blur5, X_train_aug_zca5),axis=0)\n",
    "\n",
    "y_train_all=np.concatenate((y_train_a,y_train_b,y_train_c,y_train_d,y_train_e,y_train_aug_rotate, y_train_aug_shear, y_train_aug_wshift, y_train_aug_hshift, y_train_w_h_shift,y_train_aug_blur, y_train_aug_zca,y_train_aug_rotate2, y_train_aug_shear2, y_train_aug_wshift2, y_train_aug_hshift2, y_train_w_h_shift2,y_train_aug_blur2, y_train_aug_zca2,y_train_aug_rotate3, y_train_aug_shear3, y_train_aug_wshift3, y_train_aug_hshift3, y_train_w_h_shift3,y_train_aug_blur3, y_train_aug_zca3,y_train_aug_rotate4, y_train_aug_shear4, y_train_aug_wshift4, y_train_aug_hshift4, y_train_w_h_shift4,y_train_aug_blur4, y_train_aug_zca4,y_train_aug_rotate5, y_train_aug_shear5, y_train_aug_wshift5, y_train_aug_hshift5, y_train_w_h_shift5,y_train_aug_blur5, y_train_aug_zca5),axis=0)\n",
    "\n",
    "X_train_all = np.reshape(X_train_all,(-1,RESIZE_DIM,RESIZE_DIM, 1 ))\n",
    "X_train_all.shape , y_train_all.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "620a40d9-36f8-49fa-b96c-b823999daad0",
    "_uuid": "1d06bb5aaa056f719a918be3206c3f6b2e738e0b",
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_test_a=get_data(paths_test_a,resize_dim=RESIZE_DIM)\n",
    "X_test_b=get_data(paths_test_b,resize_dim=RESIZE_DIM)\n",
    "X_test_c=get_data(paths_test_c,resize_dim=RESIZE_DIM)\n",
    "X_test_d=get_data(paths_test_d,resize_dim=RESIZE_DIM)\n",
    "X_test_e=get_data(paths_test_e,resize_dim=RESIZE_DIM)\n",
    "X_test_f=get_data(paths_test_f,resize_dim=RESIZE_DIM)\n",
    "X_test_auga=get_data(paths_test_auga,resize_dim=RESIZE_DIM)\n",
    "X_test_augc=get_data(paths_test_augc,resize_dim=RESIZE_DIM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting the test data (But we do not have the validation for test data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "59775980271bb7f31fea8f546f7e8189724f6d49",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_test_all=np.concatenate((X_test_a,X_test_b,X_test_c,X_test_d,X_test_e,X_test_f,X_test_auga,X_test_augc))\n",
    "X_test_all = np.reshape(X_test_all,((-1,RESIZE_DIM,RESIZE_DIM, 1 )))\n",
    "X_test_all.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Making test-train split from our test data\n",
    "\n",
    "### Since we don't have the validation for test data so we are spliting the train data in 80% and 20%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "45550d4b-7b11-4277-b968-3cbc74161537",
    "_uuid": "ec1470e959cf087a27d9ca3d349f2f5dd8687528",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "indices=list(range(len(X_train_all)))\n",
    "np.random.seed(42)\n",
    "np.random.shuffle(indices)\n",
    "\n",
    "ind=int(len(indices)*0.80)\n",
    "# train data\n",
    "X_train=X_train_all[indices[:ind]] \n",
    "y_train=y_train_all[indices[:ind]]\n",
    "\n",
    "# validation data\n",
    "X_val=X_train_all[indices[-(len(indices)-ind):]] #-ve indexing means start from the last \n",
    "# -1 means the last element similarly -2 means the 2nd last element and -n mens the nth ast element\n",
    "\n",
    "y_val=y_train_all[indices[-(len(indices)-ind):]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "32382aae-4756-457e-af68-5fd94603ddfb",
    "_uuid": "ba5d4e25fb97b4afcb84f85c8788da6244afadaf"
   },
   "source": [
    "\n",
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "1fae5204-6082-410a-a111-375880df9e70",
    "_uuid": "8135539c275b5af142096a33acfba7cc30aa2f8f",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_model():\n",
    "    input_layer=Input(shape=(RESIZE_DIM,RESIZE_DIM,1))\n",
    "    x=Conv2D(filters=32,kernel_size=(3,3),padding='same', activation='relu')(input_layer)\n",
    "    x=Conv2D(filters=32,kernel_size=(3,3),padding='same', activation='relu')(x)\n",
    "    x=MaxPool2D(pool_size=(2,2),strides=2,padding='valid')(x)\n",
    "    \n",
    "    \n",
    "    x=Conv2D(filters=64,kernel_size=(3,3),padding='same', activation='relu')(input_layer)\n",
    "    x=Conv2D(filters=64,kernel_size=(3,3),padding='same', activation='relu')(x)\n",
    "    x=MaxPool2D(pool_size=(2,2),strides=2,padding='valid')(x)\n",
    "    \n",
    "    x=Conv2D(filters=128,kernel_size=(3,3),padding='same', activation='relu')(x)\n",
    "    x=Conv2D(filters=128,kernel_size=(3,3),padding='same', activation='relu')(x)\n",
    "    x=MaxPool2D(pool_size=(2,2),strides=2,padding='valid')(x)\n",
    "    \n",
    "    \n",
    "    x=Conv2D(filters=256,kernel_size=(3,3),padding='same', activation='relu')(x)\n",
    "    x=Conv2D(filters=256,kernel_size=(3,3),padding='same', activation='relu')(x)\n",
    "    x=MaxPool2D(pool_size=(2,2),strides=2,padding='valid')(x)\n",
    "    \n",
    "    x=Conv2D(filters=512,kernel_size=(3,3),padding='same', activation='relu')(x)\n",
    "    x=Conv2D(filters=512,kernel_size=(3,3),padding='same', activation='relu')(x)\n",
    "    x=MaxPool2D(pool_size=(2,2),strides=2,padding='valid')(x)\n",
    "    \n",
    "    x=Flatten()(x)\n",
    "    x=Dense(units=512, activation='relu', W_constraint=maxnorm(3))(x)\n",
    "    x=Dense(units=1024, activation='relu', W_constraint=maxnorm(3))(x)\n",
    "    x=Dense(units=256, activation='relu', W_constraint=maxnorm(3))(x)\n",
    "    x=Dense(units=10)(x)    \n",
    "    output_layer=Activation('softmax')(x)\n",
    "    model=Model(inputs=input_layer,outputs=output_layer)\n",
    "    model.compile(loss='categorical_crossentropy',metrics=['accuracy'],optimizer='adam')\n",
    "    return model\n",
    "\n",
    "\n",
    "\n",
    "model=get_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "ee9607d4-40d3-449d-948d-ca743a6f9d77",
    "_uuid": "0b0adac9af387df7adc0cf26954802305849396e"
   },
   "source": [
    "# Train and Validate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "7b15bdc9-1794-4eda-9d48-f544be3e382c",
    "_uuid": "f220f61fae1fae8c1cfb2f843300b489937b0090",
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "weight_file='best.hdf5' # save best model at this location after each epoch\n",
    "check  = ModelCheckpoint(weight_file, monitor = 'val_acc', verbose=1, save_best_only=True, mode= max )\n",
    "checkpoints = [check]\n",
    "K.tensorflow_backend.clear_session() # destroys the current graph and builds a new one\n",
    "model=get_model() # create the model\n",
    "K.set_value(model.optimizer.lr,1e-4) # set the learning rate\n",
    "# fit the model\n",
    "\n",
    "#model.load_weights('best.hdf5')\n",
    "h=model.fit(x=X_train,     \n",
    "            y=y_train, \n",
    "            batch_size=64, \n",
    "            epochs=20, \n",
    "            verbose=1, \n",
    "            validation_data=(X_val,y_val),\n",
    "            shuffle=True,\n",
    "            callbacks = checkpoints\n",
    "            )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "79cdb9efb315d754ff01622339790165627e26df"
   },
   "source": [
    "# Make Predictions on Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "3a9be8aca2141ea5a8b597cb79bba180ca725555",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.load_weights(weight_file)\n",
    "predictions_prob=model.predict(X_test_all) # get predictions for all the testing data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "1cdfc83f7f114b3b219794ba3147fed979849360"
   },
   "source": [
    "### Let's observe a few predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "f161da71ffe8853fbbe24ba4b83ad08183a87590",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_sample=200\n",
    "np.random.seed(42)\n",
    "ind=np.random.randint(0,len(X_test_all), size=n_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "39f97b94480fed8d75c50ba1eea00a5f8f6b8fa9",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_test_all = np.reshape(X_test_all,(-1,RESIZE_DIM,RESIZE_DIM)) #reshaping to plot the images\n",
    "imshow_group(X=X_test_all[ind],y=None,y_pred=predictions_prob[ind])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "1e585b35a251a3a927b85bb7800f7eebe2aa149a"
   },
   "source": [
    "# Create Submission File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "127814729b7274f650f514ffa528fd6ffeb3ebcc",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "labels=[np.argmax(pred) for pred in predictions_prob]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "0755ede1693a11167d26c4c8035252226b3b797d",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "keys=[get_key(path) for path in paths_test_all ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "e505c28b44ccc5942280a9777ae2c0c19a1b487c",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "create_submission(predictions=labels,keys=keys,path='file2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "0f19d53dbe9d83dbcf898789a74d859a5d21454b",
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
